{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb2931e6-c9f0-4f70-a9ab-b7b89f7f20ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from netCDF4 import Dataset\n",
    "from fvcom import FvcomGrid\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e98f86-10fc-4088-bd7e-18d9846ea28a",
   "metadata": {},
   "source": [
    "Get some FVCOM output to examine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a456a77a-f5f7-43f3-9d87-2c177c7446a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<class 'netCDF4._netCDF4.Dataset'>\n",
       "root group (NETCDF3_CLASSIC data model, file format NETCDF3):\n",
       "    title: FVCOM Velocity Blockage Test(Updated Block with Kelp June 2013)                 \n",
       "    institution: School for Marine Science and Technology\n",
       "    source: FVCOM_2.7\n",
       "    history: model started at: 17/08/2022   07:51\n",
       "    references: http://fvcom.smast.umassd.edu\n",
       "    Conventions: CF-1.0\n",
       "    dimensions(sizes): scalar(1), node(16012), nele(25019), siglay(10), siglev(11), three(3), four(4), obc(87), obc2(87), time(24)\n",
       "    variables(dimensions): int32 nprocs(scalar), int32 partition(nele), float32 Initial_Density(siglay, node), float32 x(node), float32 y(node), float32 lon(node), float32 lat(node), float32 siglay(siglay), float32 siglay_shift(siglay), float32 siglev(siglev), float32 h(node), float32 nv(three, nele), float32 a1u(four, nele), float32 a2u(four, nele), float32 aw0(three, nele), float32 awx(three, nele), float32 awy(three, nele), float32 time(time), int32 iint(time), float32 u(time, siglay, nele), float32 v(time, siglay, nele), float32 ww(time, siglay, nele), float32 wts(time, siglev, node), float32 uard_obcn(time, obc), float32 xflux_obc(time, siglay, obc2), float32 dtfa(time, node), float32 kh(time, siglev, node), float32 zeta(time, node), float32 salinity(time, siglay, node), float32 temp(time, siglay, node)\n",
       "    groups: "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = Dataset('/net/babaracus/home/benr/wqmodels/ssm/unionriver/hyd/1x_1pass/OUTPUT/netcdf/ssm_00001.nc')\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f371d7-cd22-4084-a12a-7afa757b6496",
   "metadata": {},
   "source": [
    "Define the important parts of a section needed for this proof-of-concept. We need to know an element, plus the previous and next adjacent elements in the section.\n",
    "\n",
    "This code does not handle edge elements properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97ae1c09-ab82-4bc2-a0ae-bfd37ebd10b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_ele = 7823\n",
    "ele = 7652\n",
    "next_ele = 7653"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3fc989c8-bc98-4f08-94b2-8cfe2f693ab3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(516422.8, 5332524.5, 516387.94, 5333294.0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid = FvcomGrid.from_output(ds, calc=True)\n",
    "neis = (grid.nbe[:,ele-1]-1).T\n",
    "neis = neis[~(neis == -1)]\n",
    "which_prev_nei = (grid.nbe[:, ele-1] == prev_ele).nonzero()[0]\n",
    "non_nei_idxs = (np.arange(3) != which_prev_nei).nonzero()[0]\n",
    "common_nodes = grid.nv[non_nei_idxs, ele-1]\n",
    "xm1, ym1 = grid.ncoord[0:2, common_nodes-1].mean(axis=1)\n",
    "\n",
    "which_next_nei = (grid.nbe[:, ele-1] == next_ele).nonzero()[0]\n",
    "non_nei_idxs = (np.arange(3) != which_next_nei).nonzero()[0]\n",
    "common_nodes = grid.nv[non_nei_idxs, ele-1]\n",
    "xm2, ym2 = grid.ncoord[0:2, common_nodes-1].mean(axis=1)\n",
    "xm1, ym1, xm2, ym2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4391ce6b-a03a-4ea9-b338-4bbad32fe5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = grid.elcoord[0:2, ele-1]\n",
    "dx1 = xm1 - x\n",
    "dy1 = ym1 - y\n",
    "th1 = np.arctan2(-dy1, -dx1)\n",
    "th1 = np.where(th1 < 0, th1 + 2 * np.pi, th1) - np.pi / 2 % (2 * np.pi)\n",
    "dx2 = xm2 - x\n",
    "dy2 = ym2 - y\n",
    "th2 = np.arctan2(dy2, dx2)\n",
    "th2 = np.where(th2 < 0, th2 + 2 * np.pi, th2) - np.pi / 2 % (2 * np.pi)\n",
    "n1 = np.array([np.cos(th1), np.sin(th1)])\n",
    "n2 = np.array([np.cos(th2), np.sin(th2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21a7ce6e-7d0d-495a-b7f6-4f32a648b8a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(masked_array(data=[-0.31615293,  0.04517227,  0.05778968],\n",
       "              mask=False,\n",
       "        fill_value=1e+20,\n",
       "             dtype=float32),\n",
       " masked_array(data=[ 0.39888147, -0.18213874, -0.06463821],\n",
       "              mask=False,\n",
       "        fill_value=1e+20,\n",
       "             dtype=float32),\n",
       " array([[ 326.59375,  677.5    ],\n",
       "        [ 444.34375, -473.5    ],\n",
       "        [-737.21875,   11.     ]], dtype=float32))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "us = ds['u'][:,:,neis]\n",
    "vs = ds['v'][:,:,neis]\n",
    "du = (us.T - ds['u'][:,:,ele-1].T).T\n",
    "dv = (vs.T - ds['v'][:,:,ele-1].T).T\n",
    "dxy = (grid.elcoord[0:2,neis].T - grid.elcoord[0:2,ele-1].T)\n",
    "du[20,2], dv[20,2], dxy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc5e756-3e8d-49f8-8229-4995bd2f5b70",
   "metadata": {},
   "source": [
    "This is the manual way: compute the least-squares coefficients for each velocity component, at every sigma layer, at every timestep. This is $O(2 K_B N)$. This is going to be sloooow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c2457d5-a44a-4e0e-9a42-7bc1734750c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.00014728414, -0.0003432317)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "au, bu = np.linalg.lstsq(dxy, du[20,2], rcond=None)[0]\n",
    "av, bv = np.linalg.lstsq(dxy, dv[20,2], rcond=None)[0]\n",
    "au, bu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca1ec8b-2501-4ba6-8e68-c868a1890900",
   "metadata": {},
   "source": [
    "The more efficient method is to compute the pseudo-inverse of dxy, which can then be multiplied with each velocity difference to get coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb455758-6466-4a61-9aae-964c319f25dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.8209284e-04,  5.2650401e-04, -8.6983963e-04],\n",
       "       [ 9.8992500e-04, -6.9505814e-04,  1.9612371e-05]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dxy_pinv = np.linalg.pinv(dxy)\n",
    "dxy_pinv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5cda4f48-336e-4413-855c-26211f5420da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "masked_array(data=[-0.00014728, -0.00034323],\n",
       "             mask=False,\n",
       "       fill_value=1e+20,\n",
       "            dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dxy_pinv @ du[20,2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b111796c-7f6c-43ac-bb8f-8af37bf6d5b1",
   "metadata": {},
   "source": [
    "The uniform velocity model (what Conroy's code does).\n",
    "\n",
    "Assume the velocity at the centroid is a good estimate of the velocity throughout the element. Then, to get the transport flux, just dot with the normal to each segment (side midpoint to centroid) and scale by the segment length over the total length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d269aa13-611f-4699-a6ef-5ce2888b7f47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.7855390714137171"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u0 = ds['u'][:,:,ele-1]\n",
    "v0 = ds['v'][:,:,ele-1]\n",
    "l1 = np.sqrt(dx1 ** 2 + dy1 ** 2)\n",
    "l2 = np.sqrt(dx2 ** 2 + dy2 ** 2)\n",
    "l = l1 + l2\n",
    "tf_uniform = l1/l * (u0[20,2] * n1[0] + v0[20,2] * n1[1]) + l2/l * (u0[20,2] * n2[0] + v0[20,2] * n2[1])\n",
    "tf_uniform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91af4f74-875d-4b73-921b-5042a26caacb",
   "metadata": {},
   "source": [
    "The least-squares velocity model. This is derived from the FVCOM manual to get velocity through the same segments that Conroy uses, but without assuming uniform velocity.\n",
    "\n",
    "The transport through the element per unit length of segment is a line integral:\n",
    "\n",
    "$TF*l = \\int \\vec{u} \\cdot \\vec{n} ds$\n",
    "\n",
    "Decompose into each segment and parameterize the line integral, treating the centroid as the origin of the coordinate system and the side midpoints as $(x_1, y_1)$ and $(x_2, y_2)$:\n",
    "\n",
    "$y = y_1 t$ (or $y_2 t$)\n",
    "\n",
    "$x = x_1 t$ (or $x_2 t$)\n",
    "\n",
    "$TF*l = \\int_{t=0}^1 ((un_{x,1} + vn_{y,1}) \\sqrt{x_1^2 + y_1^2} + (un_{x,2} + vn_{y,2})\\sqrt{x_2^2 + y_2^2})dt$\n",
    "\n",
    "Let $l_j = \\sqrt{x_j^2 + y_j^2}$. Equations for $u$ and $v$ are in the FVCOM manual (3.20 and 3.21). Substitute:\n",
    "\n",
    "$TF*l = \\int_{t=0}^1 (n_{x,1}(u_0 + a^u x_1 t + b^u y_1 t) + n_{y,1}(v_0 + a^v x_1 t + b^v y_1 t))l_1 + (n_{x,2}(u_0 + a^u x_2 t + b^u y_2 t) + n_{y,2}(u_0 + a^v x_2 t + b^v y_2 t))l_2)dt$\n",
    "\n",
    "Integrating gives the following result:\n",
    "\n",
    "$TF = \\frac{l_1}{l} (n_{x,1} (u_0 + 0.5 (a^u x_1 + b^u y_1)) + n_{y,1}(v_0 + 0.5 (a^v x_1 + b^v y_1))) + \\frac{l_2}{l} (n_{x,2} (u_0 + 0.5 (a^u x_2 + b^u y_2)) + n_{y,2}(v_0 + 0.5 (a^v x_2 + b^v y_2)))$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b025c91-d88f-4955-ab58-5687d0ff1911",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.8545657243944654"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "au, bu = dxy_pinv @ du[20,2]\n",
    "av, bv = dxy_pinv @ dv[20,2]\n",
    "tf_lstsq = (l1 * (n1[0] * (u0[20,2] + 0.5 * (au * dx1 + bu * dy1))\n",
    "        + n1[1] * (v0[20,2] + 0.5 * (av * dx1 + bv * dy1))\n",
    "      ) + l2 * (n2[0] * (u0[20,2] + 0.5 * (au * dx2 + bu * dy2))\n",
    "        + n2[1] * (v0[20,2] + 0.5 * (av * dx2 + bv * dy2))\n",
    "    )) / l\n",
    "\n",
    "tf_lstsq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fcc88a0-5b7d-4c31-a3fe-3843007098a0",
   "metadata": {},
   "source": [
    "The above procedure works well, but it's not implemented efficiently since it depends on performing $O(K_B N)$ matrix multiplications to get all of the $a$ and $b$ constants. A more efficient method is to reshape $du$ and $dv$ into matrices that have one row per element neighbor, and the columns contain flattened values of $u$ and $v$ at different sigma levels and times. Multiplying the pseudo-inverse with each reshaped matrix will give matrices containing all of the constants $a^u, b^u. a^v, b^v$, which must be reshaped back. Then the transport function can be computed in a single line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "81ef7b0a-bb13-4830-af64-0225a1447e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "du_reshape = du.T.reshape(du.shape[2], (du.shape[0]*du.shape[1])).data\n",
    "dv_reshape = dv.T.reshape(dv.shape[2], (dv.shape[0]*dv.shape[1])).data\n",
    "assert (du[20,2] == du_reshape[:,2 * du.shape[0] + 20]).all()\n",
    "abu_reshape = dxy_pinv @ du_reshape\n",
    "abv_reshape = dxy_pinv @ dv_reshape\n",
    "assert (np.abs(np.array([au, bu]) - abu_reshape[:,2 * du.shape[0] + 20]) < 0.000001).all()\n",
    "\n",
    "abu = abu_reshape.reshape(2, du.shape[1], du.shape[0]).T\n",
    "abv = abv_reshape.reshape(2, dv.shape[1], dv.shape[0]).T\n",
    "assert (np.abs(np.array([au, bu]) - abu[20,2]) < 0.000001).all()\n",
    "\n",
    "tf_lstsq_noloop = (l1 * (n1[0] * (u0 + 0.5 * (abu[:,:,0] * dx1 + abu[:,:,1] * dy1))\n",
    "                         + n1[1] * (v0 + 0.5 * (abv[:,:,0] * dx1 + abv[:,:,1] * dy1))\n",
    "                        ) + l2 * (n2[0] * (u0 + 0.5 * (abu[:,:,0] * dx2 + abu[:,:,1] * dy2))\n",
    "                                  + n2[1] * (v0 + 0.5 * (abv[:,:,0] * dx2 + abv[:,:,1] * dy2))\n",
    "                                 )) / l\n",
    "assert tf_lstsq - tf_lstsq_noloop[20,2] < 0.000001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb18861-8ec5-47c1-9054-ec8ff7581c64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ssm-analysis]",
   "language": "python",
   "name": "conda-env-ssm-analysis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
